{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    \"\"\"\n",
    "    Applies the sigmoid function elementwise to the input data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t : array, arbitrary shape\n",
    "        Input data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    t_sigmoid : array, arbitrary shape.\n",
    "        Data after applying the sigmoid function.\n",
    "    \"\"\"\n",
    "    t_sigmoid = 1/(1+np.exp(-t))\n",
    "    return t_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 5]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[2,3,5],[4,5,6]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88079708 0.95257413 0.99330715]\n",
      " [0.98201379 0.99330715 0.99752738]]\n"
     ]
    }
   ],
   "source": [
    "a_sig = sigmoid(a)\n",
    "print(a_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "b = 0.0\n",
    "\n",
    "b += 1\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(X, y, w):\n",
    "    nll = 0\n",
    "    for i in range (0,10):\n",
    "        nll+=i\n",
    "    return -nll\n",
    "                                                                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-45\n"
     ]
    }
   ],
   "source": [
    "print(negative_log_likelihood(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_log_likelihood(X, y, w):\n",
    "    \"\"\"\n",
    "    Negative Log Likelihood of the Logistic Regression.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape [N, D]\n",
    "        (Augmented) feature matrix.\n",
    "    y : array, shape [N]\n",
    "        Classification targets.\n",
    "    w : array, shape [D]\n",
    "        Regression coefficients (w[0] is the bias term).\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    nll : float\n",
    "        The negative log likelihood.\n",
    "    \"\"\"\n",
    "    nll = 0.0\n",
    "    print(nll)\n",
    "    for i in range(len(y)):\n",
    "        print(i)\n",
    "        nll += y[i]*np.log(sigmoid(np.matmul(w,X[i]))) + (1-y[i])*np.log(1-sigmoid(np.matmul(w,X[i])))\n",
    "        print(nll)\n",
    "    return -nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[-1  0  1]\n",
      "[0 1 0 1]\n",
      "2\n",
      "0.8807970779778823\n",
      "-2.1269280110429714\n",
      "0.0\n",
      "0\n",
      "-2.1269280110429714\n",
      "1\n",
      "-2.253856022085944\n",
      "2\n",
      "-4.380784033128915\n",
      "3\n",
      "-4.507712044171887\n",
      "4.507712044171887\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "print(X[0])\n",
    "w = np.array([-1,0,1])\n",
    "print(w)\n",
    "y = np.array([0,1,0,1])\n",
    "print(y)\n",
    "print(np.matmul(w,X[0]))\n",
    "print(sigmoid(np.matmul(w,X[0])))\n",
    "print(np.log(1-sigmoid(np.matmul(w,X[0]))))\n",
    "print(negative_log_likelihood(X, y, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.31528373e-07 -1.40000008e+01 -8.31528373e-07 -1.40000008e+01]\n",
      "[8.31528373e-07 1.40000008e+01 8.31528373e-07 1.40000008e+01]\n"
     ]
    }
   ],
   "source": [
    "print(negative_log_likelihood(X, y, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.zeros(len(a))\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "I = np.identity(3)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(X, y, w, mini_batch_indices, lmbda):\n",
    "    \"\"\"\n",
    "    Calculates the gradient (full or mini-batch) of the negative log likelilhood w.r.t. w.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array, shape [N, D]\n",
    "        (Augmented) feature matrix.\n",
    "    y : array, shape [N]\n",
    "        Classification targets.\n",
    "    w : array, shape [D]\n",
    "        Regression coefficients (w[0] is the bias term).\n",
    "    mini_batch_indices: array, shape [mini_batch_size]\n",
    "        The indices of the data points to be included in the (stochastic) calculation of the gradient.\n",
    "        This includes the full batch gradient as well, if mini_batch_indices = np.arange(n_train).\n",
    "    lmbda: float\n",
    "        Regularization strentgh. lmbda = 0 means having no regularization.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dw : array, shape [D]\n",
    "        Gradient w.r.t. w.\n",
    "    \"\"\"\n",
    "    \n",
    "    N_mini = len(mini_batch_indices)\n",
    "    I = np.identity(len(w))\n",
    "    \n",
    "    for i in range(N_mini):\n",
    "        t = mini_batch_indices[i]\n",
    "        dw_temp += -y[t]*X[t] + ((np.exp(np.matmul(X[t],w)))/(1+(np.exp(np.matmul(X[t],w)))))*X[t]\n",
    "    \n",
    "    dw = (1/len_m)*dw_temp + lmbda*(np.matmul(I,w))\n",
    "    return dw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "print(X[0])\n",
    "w = np.array([-1,0,1])\n",
    "print(w)\n",
    "y = np.array([0,1,0,1])\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
